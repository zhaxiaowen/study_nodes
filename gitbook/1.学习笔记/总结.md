# 总结

#### 云原生运维

> 运维的本质:多个运营事件的有机串联,来达到质量、效率、成本、安全多维收益,而编排是实现有机串联的有效手段

* 具备服务全链路质量监控覆盖,涵盖数据域域业务域:
  * 全链路监控,skyworking,pinpoint
* 具备一定智能化的资源动态调度、伸缩机制:
  * 有良好的扩缩容标准,才能具体的执行资源动态调度和扩缩容
* 具备一定的故障预警、根因分析、问题定位能力:
  * 良好的监控体系,能够在生产发生故障前就预警出来
* 服务具备在交付不同阶段(测试、预发布、运营)抵御异常的能力:
  * 标准的环境规范,确保各个环境的一致性
* 具备资源高效交付的流程机制与快速上线的能力:
  * 具有标准的上线流程
  * 能够实现各个组件的自动化部署
* 具备多云的资源编排与管理能力:
  * 服务部署双云,确保业务的可持续性和高可用性
* 具备业务快速上云的机制,确保切换过程的高可用性:
  * 业务上云的切换方案
  * 中间件上云的数据同步
  * 双云切换如何做到快速、业务侧无感知
  * 定期故障演练

#### 运维工作意识

1. 独立思考的能力非常重要,不要人云亦云,一定要坚持去独立思考,知道自己需要什么,自己的目标是什么
2. 细心、细致对研发、运维都是非常重要的,需要细心的去做事,越细致就越能看到一些问题
3. 要不断迭代,敢于创新去使用新技术,不要固守成规,不要守旧,为我们系统稳定运行提供保障
4. 安全是运维重中之重,包括安全漏洞修复、防止数据泄露、安全稳定的发布版本.随着用户规模逐渐达到百万级,我们需要确保发版安全,确保平台稳定运行,所以A/B Test、灰度发布的机制要建立起来
5. 运维也需要关注业务、熟悉业务,要注意多去看业务数据,对业务越了解,就对用户越了解,这样能做到对业务平台的运行心里有数、有把控,对做一些预判是很有帮助的
6. 持续推进DevOps,提高自动化,提高效率,多让机器帮我们做事情,保持跟开发的紧急协作,持续赋能业务开发的持续交付
7. 安全与稳定是务必注意与注重的

#### 灰度

* 资源隔离:蓝绿集群
* 不同组隔离的资源:
  * motan rpc
  * mq topic
  * elastic-job定时任务(灰度集群不执行elastic-job定时任务)
* 不同组公用的资源:
  * mysql,mongo,redis
  * 业务中台接口;数据中台接口
* 公共配置:
  * gray.deploy.status=true/false
  * gray.deploy.group=blue/green
  * 调度服务mysql数据分组,灰度集群只调度灰度司机
  * 在redis给司机打分组标签;根据redis分组标签过滤司机

# 总结

1. 架构:公司的架构,灾备;熟悉分布式架构运行的原理； 高可用、高性能，安全性、可扩展性、可维护性、可伸缩性  

2. 监控方案:promethesu,zabbix,pinpoint(全链路追踪),

3. 高可用方案:制定、实施与部署; 
   
   * [饿了么异地多活技术实现](https://zhuanlan.zhihu.com/p/32009822)
   * [bilibili高可用架构](https://zhuanlan.zhihu.com/p/139258985)

4. 自动化:熟悉jenkins,会编写jenkinsfile,熟悉maven编译,ansible;推动自动化;devops;怎么理解CI/CD?

5. 故障处理:

6. 性能优化:linux,中间件

# 思考

>  运维的职责

1. 负责现网的正常运行
2. 很大一部分生产故障都是由于变更导致的，如何减少变更导致的故障，需要考虑
3. 减少运维变更过程中的手动变更，尽量提高自动化水平
4. 完善自动化工具
5. 严格按照变更文档执行变更，有问题及时停止变更
6. 不止要做好当下工作,最好能够多与研发交流,比如说咨询研发,他们的es结构设计,kafka等等,一方面可以提高自己,另一方面,也能加深对组件的使用了解,方便后续性能优化

### 自动化能力建设

1. 新申请的服务器,监控,ansible配置,配置秘钥免密登录

#### 好的架构

```yaml
健壮的系统的特性:高可用、高性能，安全性、可扩展性、可维护性、可伸缩性

高性能：用户量的保证前提
  前端优化
  应用优化
  数据库优化
高可用：保证服务器不宕机
  数据备份
  自动发布
  灰度发布
  监控报警
可扩展：分布式系统，集群
  负载均衡
  缓存负载均衡
  分布式消息
  服务化
安全性：预防网站的各种攻击
  XSS攻击
  SQL注入缓存负载均衡
  CSRF攻击
  防火墙漏洞
```

A:

* 系统可用性改造,主要针对java应用,nginx,redis,mysql进行改造
* 系统接入CI/CD,接入监控
* 针对系统的资源使用情况,做升配、降配
* 制定故障演练方案,每季度演练

B:

* 负责4个业务20套cassandra集群运维
* 针对集群做性能优化,比如集群QPS/CPU/磁盘等达到扩容标准,但业务侧不想扩容,协助业务侧做优化,比如减少TTL时间;每天1000+的接口报错问题定位;
* 集群拆分:push集群1拆4;云服务集群1拆10
* 推动运维平台的使用:推动运维SaaS平台落地,测试使用,提bug单给运维开发;180套集群接入Saas平台运维
* 提高自动化运维能力:数据一致性比对,通过脚本分析结果

C:

* 系统稳定性优化:拆分接口
* 自动化能力建设:将以前用脚本实现的部分功能,通过Jenkins Job实现,使用更加规范,标准
  * 通过Jenkins实现中间件的部署
  * 通过Jenkins添加监控
  * 通过python脚本,实现apollo新集群的配置添加
* 灾备机房部署:切换方案是通过域名解析新地址实现
  * 前期整改:配置文件中通过ip连接的,提前整改,lb整改
  * 中间件迁移,redis迁移到腾讯云redis
  * 服务清单整理
  * 应用和中间件部署
  * 应用起包
* 测试环境迁移腾讯云TKE集群
  * 前期:Jenkins目前不支持自动创建凭证，需要手动配置namespace和namespace对应仓库凭证
  * 安全组放行,添加DNS解析
  * 基础服务部署:redis,mongo,mysql,kafka,nacos,MQ等
  * apollo配置修改
  * 通过jenkins部署
  * 验证服务是否可以正常访问

### A公司:

产品运维,岗位职责

1. 系统高可用行改造
2. 系统应用标准改造:打包方式,应用目录,应用日志,运行参数;部署目录,缓存目录,日志目录,临时目录
3. 系统接入CI/CD自动化部署,日常巡检
4. 监控接入,监控优化(NAS监控)
5. 制定、并组织故障演练方案
6. 资源评估,释放资源
7. 20套系统的mysql数据库迁移

故障

1. 思科超融合虚拟平台bug,导致10多套系统故障

2. 暴露出平时工作的一些问题:
- 部分应用开机自启未生效

- 部分应用的所有节点都在这个虚拟平台,导致即使做了高可用改造,还是没用

- 监控不到位,没有可视化显示一个系统哪些服务处故障
3. NFS远程存储服务未监控，导致服务断开了，不知晓，直到业务找来
- 添加监控

### B公司

中间件运维;岗位职责

cassandra数据库;es集群运维;redis集群运维;kafka集群运维

1. 中间件运维

2. 推动自动化运维,运维平台落地

3. 业务性能优化:(容量;每日报错次数优化;)

4. 集群拆分

5. 日常巡检,结果用即席查询显示在AIOPS平台上

故障

1. redis集群扩容后,mget指令有明显时延变多

2. 数据修复,导致磁盘IO阻塞,影响生产

3. 扩容脚本bug,grep $ip不是精确匹配,导致主站IP扩容到备站

4. push集群拆分时,ttl时间未同步准确,本来保存1天的数据,保存了3天,导致集群出现大量compaction

### C公司

业务运维,岗位职责

1. 系统稳定性优化
2. 灾备机房部署(提前整改了redis和配置文件):阿里云GTM实现容灾切换(https://help.aliyun.com/document_detail/409481.html)
3. 所有redis切云redis服务
4. kafka集群版本升级(1.版本升级,并兼容旧版本协议)
5. 相关业务配置文件改造,所有ip改造成域名连接
6. 文档梳理,规范变更文档
7. 写jenkins的pipline,来自动化部署应用,prometheus配置文件更新,通过jenkins下发到服务器上

故障

不规范：

比如说查看监控，我们习惯用主机名看，但是部分主机名不规范，可能导致漏看

### D公司

业务运维,岗位职责

1. 测试环境app服务容器化,腾讯云TKE

* 基础组件脚本编写,部署完成后测试dev环境的主流程

* uat环境的skywalking和jmx监控,添加业务监控

  

```
1.基础镜像选取:
os:
jdk:

一.TKE相关工作:
    TKE环境初始化:  Ingress,namespace,仓库凭据等
    Jenkins配置: app任务
    kubesphere配置： 权限，企业空间
    日志配置： 生成新logstash
二.网络:安全组
三.基础服务部署:
    app服务:单独部署
    apollo
    网关配置,dns修改
    数据库:单独部署,同步数据
四.切换
    关闭app后端服务,修改git,cmdb配置
    修改域名解析
    网络隔离,拒绝非容器环境访问数据库
    entbus apollo配置修改
    开始容器化部署
五.验证
    验证容器服务是否正常启动
    管理后台验证:域名是否正常访问、登录
    功能验证
    文档修改

遇到问题:
1.管理后台无法加载验证码
    原因:前端项目打包还是旧打包，需要配置npm  run build 环境变量 
    处理:需要关联旧接口
2.容器存活探针一直失败,导致服务重启
    原因:查看日志,发现应用连接数据库信息错误,数据库账号不对,少了最后几个字母;
    历史遗留问题:由于以前数据库对应字段长度设置为128,数据库名经过base64加密后,长度超过,所以手动把库名减少了几位,本次迁移过程中暴露出来
3.网络不通
4.验证时,域名无法访问:未创建ingress
5.容器挂在的证书过期,需要手动去修改每个环境的configmap
```

#### 问题总结:

1. 服务间耦合度高
2. 应用的trace id和skywalking的不同
3. 技术债问题,比如说前端域名跟前端服务名不一致,后续规划的是域名的前缀做服务名
4. 9套fat环境供不同项目使用,apollo的配置同步如何很好的实现?目前是测试同事来管理

### 个人优缺点

1. 做事还算细心
2. 会定期反思自己,最近做事是否有不足,是否有待提高的
3. 总结,对比,比如以前公司有些做的好的地方,这家公司这边没有,可以主动提出来完善下,比如说导航文档,运维涉及到的权限等
4. 做事相对细心一点,事前过一遍,事中会保留一些日志/截图之类的东西,事后再验证一下

### 能做什么

1. 入职规范文档,比如运维需要用到哪些平台,要找哪些人申请权限

2. 运维故障、经验文档总结

3. 制定合理的扩缩容标准

4. 提升运维变更的自动化能力,比如中间件部署,常见变更等

5. 通过kibana监控业务指标,日志错误量,mysql连接异常等

6. 改造:
   * jenkins上job的分类太多,有blue,public等,有些批量job需要指定blue还是public环境,会影响批量任务的执行;
   * cicd的发版流程,经常会出现一些服务名写错,抄送相关人员缺少,发版时间随意写等问题,运维这边能解决的就这边解决,解决不了的沟通研发,比如说抄送人员,找运开写死抄送人员,直接抄送整个组的,不用研发再手动填写
   * cmdb平台,生成nginx配置,要手动点下生成nginx配置,然后jenkins任务下发,才会生成,找运开修改
   * 发版时,明明有屏蔽告警的操作,但是有些服务还是会告警,找运开看,发现是因为服务名和model名,大部分是相同的,但是有些不同的,改成用model名去屏蔽告警

7. 监控、告警:

   * 通过Kibana监控业务,中间件的错误日志
   * skyworking全链路监控
   * 接口优化,部分业务的接口请求时间过长,甚至有10s,找研发优化,

8. 问题:

    * 有时服务发版本时,会报端口被占用,查看时发现服务已经停了,但是有时lsof -i:port会发现端口还有连接

|       |                                                                                                                   |                                 |
| ----- | ----------------------------------------------------------------------------------------------------------------- | ------------------------------- |
| kafka | 5个节点<br />配置:8核32G<br />QPS:7k左右<br />3副本<br />                                                                   |                                 |
| redis | 配置:单实例8G内存<br />QPS:最高1.5W;<br />12套redis集群:<br />driver集群6个实例QPS:5W;读请求:100W                                     | 业务高峰期:下午4点<br />业务低谷期:凌晨到早上4点最低 |
| es    | 3个master3个node节点<br />master节点:4核8G内存<br />node节点:16核64G内存<br />大概8T数据<br />挂3个盘,每个盘1T<br />5天冷热数据<br />索引生命周期30天 |                                 |

#### 遇到的问题

##### 域名解析地址错误:

* 之前遇到一个问题,前端研发反馈说jenkins发版有问题,我去检查了日志,说没问题,后面让对方在代码包里新加个test文件,也生成了,证明jenkins确实没问题,又问对方是不是他代码的问题,他说测试环境是正常的;后面他说反正就是访问页面,显示的还是旧的地址;我一想会不会是其他问题,ping了下域名,发现指向的是另一个服务器;原因是刚好做了迁移,把对内的应用和对外的分开了;
* 教训:不要轻信别人的判断,要搞清楚对方的真实诉求,要独立思考,而不是基于对方的说法去做判断

##### 灰度发布:

* 灰度发布时要手动添加灰度用户,因为个人习惯,会把命令整理到一个文档里;结果某次打开了2个灰度文档,一个是上次的,一个是本次的
* 测试让我再加一个灰度用户时,搞错了,把新加的灰度用户写到上一次的文档里,然后添加到redis里了,结果就是新的灰度用户加了,但是之前的全被覆盖了;结果其他测试就又说他的灰度用户不见了,反复了几次;还好由于已经是测试快结束了,没影响到太多
* 教训:规范流程,跟测试说提前准备好灰度用户,不要再测试过程中再要求添加灰度用户
* 教训:个人习惯问题,以后还是要仔细一些

