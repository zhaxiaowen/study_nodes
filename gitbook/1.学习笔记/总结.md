# 总结

# 技能要求:

- redis
- kafka

- elk
- nginx

- tomcat
- k8s

# 加分项

- python/shell
- ansible

- promtheus
- zabbix

- CI/CD

# 岗位职责

1. 日常运维工作,如版本升级,巡检,问题定位

   - 版本升级:

   - 巡检:

   - 问题定位:
2. 中间件运维
   - 部署,调优,监控,问题处理

#### 云原生运维

> 运维的本质:多个运营事件的有机串联,来达到质量、效率、成本、安全多维收益,而编排是实现有机串联的有效手段

* 具备服务全链路质量监控覆盖,涵盖数据域域业务域:
  * 全链路监控,skyworking,pinpoint
* 具备一定智能化的资源动态调度、伸缩机制:
  * 有良好的扩缩容标准,才能具体的执行资源动态调度和扩缩容
* 具备一定的故障预警、根因分析、问题定位能力:
  * 良好的监控体系,能够在生产发生故障前就预警出来
* 服务具备在交付不同阶段(测试、预发布、运营)抵御异常的能力:
  * 标准的环境规范,确保各个环境的一致性
* 具备资源高效交付的流程机制与快速上线的能力:
  * 具有标准的上线流程
  * 能够实现各个组件的自动化部署
* 具备多云的资源编排与管理能力:
  * 服务部署双云,确保业务的可持续性和高可用性
* 具备业务快速上云的机制,确保切换过程的高可用性:
  * 业务上云的切换方案
  * 中间件上云的数据同步
  * 双云切换如何做到快速、业务侧无感知
  * 定期故障演练

# 总结

1. 架构:公司的架构,灾备;熟悉分布式架构运行的原理； 高可用、高性能，安全性、可扩展性、可维护性、可伸缩性  
2. 监控方案:promethesu,zabbix,pinpoint(全链路追踪),
3. 高可用方案:制定、实施与部署; 
   * [饿了么异地多活技术实现](https://zhuanlan.zhihu.com/p/32009822)
   * [bilibili高可用架构](https://zhuanlan.zhihu.com/p/139258985)

4. 自动化:熟悉jenkins,会编写jenkinsfile,熟悉maven编译,ansible;推动自动化;devops;怎么理解CI/CD?

5. 故障处理:

6. 性能优化:linux,中间件

# 思考

>  运维的职责

1. 负责现网的正常运行
2. 很大一部分生产故障都是由于变更导致的，如何减少变更导致的故障，需要考虑
3. 减少运维变更过程中的手动变更，尽量提高自动化水平
4. 完善自动化工具
5. 严格按照变更文档执行变更，有问题及时停止变更
5. 不止要做好当下工作,最好能够多与研发交流,比如说咨询研发,他们的es结构设计,kafka等等,一方面可以提高自己,另一方面,也能加深对组件的使用了解,方便后续性能优化

### 自动化能力建设

1. 新申请的服务器,监控,ansible配置,配置秘钥免密登录

#### 好的架构

```yaml
健壮的系统的特性:高可用、高性能，安全性、可扩展性、可维护性、可伸缩性

高性能：用户量的保证前提
  前端优化
  应用优化
  数据库优化
高可用：保证服务器不宕机
  数据备份
  自动发布
  灰度发布
  监控报警
可扩展：分布式系统，集群
  负载均衡
  缓存负载均衡
  分布式消息
  服务化
安全性：预防网站的各种攻击
  XSS攻击
  SQL注入缓存负载均衡
  CSRF攻击
  防火墙漏洞
```



### A公司:

产品运维,岗位职责

1. 系统高可用行改造
1. 系统应用标准改造:打包方式,应用目录,应用日志,运行参数;部署目录,缓存目录,日志目录,临时目录
3. 系统接入CI/CD自动化部署,日常巡检
1. 监控接入,监控优化(NAS监控)
5. 制定、并组织故障演练方案
1. 资源评估,释放资源
2. 20套系统的mysql数据库迁移

故障

1. 思科超融合虚拟平台bug,导致10多套系统故障
2. 暴露出平时工作的一些问题:

- 部分应用开机自启未生效
- 部分应用的所有节点都在这个虚拟平台,导致即使做了高可用改造,还是没用

- 监控不到位,没有可视化显示一个系统哪些服务处故障

1. NFS远程存储服务未监控，导致服务断开了，不知晓，直到业务找来

- 添加监控

### B公司

中间件运维;岗位职责

cassandra数据库;es集群运维;redis集群运维;kafka集群运维

1. 中间件运维
2. 推动自动化运维,运维平台落地

1. 业务性能优化:(容量;每日报错次数优化;)
2. 集群拆分

1. 日常巡检,结果用即席查询显示在AIOPS平台上

故障

1. redis集群扩容后,mget指令有明显时延变多
2. 数据修复,导致磁盘IO阻塞,影响生产

1. 扩容脚本bug,grep $ip不是精确匹配,导致主站IP扩容到备站
2. push集群拆分时,ttl时间未同步准确,本来保存1天的数据,保存了3天,导致集群出现大量compaction

### C公司

业务运维,岗位职责

1. 系统稳定性优化
2. 灾备机房部署(提前整改了redis和配置文件)
1. 所有redis切云redis服务
4. kafka集群版本升级(1.版本升级,并兼容旧版本协议)
1. 相关业务配置文件改造,所有ip改造成域名连接
1. 文档梳理,规范变更文档
1. 写jenkins的pipline,来自动化部署应用

故障

不规范：

比如说查看监控，我们习惯用主机名看，但是部分主机名不规范，可能导致漏看

### D公司

业务运维,岗位职责

1. 测试环境app服务容器化,腾讯云TKE

   ```
   一.TKE相关工作:
       TKE环境初始化:  Ingress,namespace,仓库凭据等
       Jenkins配置: app任务
       kubesphere配置： 权限，企业空间
       日志配置： 生成新logstash
   二.网络:安全组
   三.基础服务部署:
   	app服务:单独部署
   	apollo
   	网关配置,dns修改
   	数据库:单独部署,同步数据
   四.切换
   	关闭app后端服务,修改git,cmdb配置
   	修改域名解析
   	网络隔离,拒绝非容器环境访问数据库
   	entbus apollo配置修改
   	开始容器化部署
   五.验证
   	验证容器服务是否正常启动
   	管理后台验证:域名是否正常访问、登录
   	功能验证
   	文档修改
   
   遇到问题:
   1.管理后台无法加载验证码
   	原因:前端项目打包还是旧打包，需要配置npm  run build 环境变量 
   	处理:需要关联旧接口
   2.容器存活探针一直失败,导致服务重启
   	原因:查看日志,发现应用连接数据库信息错误,数据库账号不对,少了最后几个字母;
   	历史遗留问题:由于以前数据库对应字段长度设置为128,数据库名经过base64加密后,长度超过,所以手动把库名减少了几位,本次迁移过程中暴露出来
   3.网络不通
   4.验证时,域名无法访问:未创建ingress
   ```

   

### 个人优缺点

1. 变更之前,提前过一遍变更流程,熟悉下变更内容,减少不可控因素
2. 定期反思自己,最近做事是否有不足,是否有待提高的
3. 总结,对比,比如以前公司有些做的好的地方,这家公司这边没有,可以主动提出来完善下,比如说导航文档,运维涉及到的权限等
4. 做事相对细心一点,事前过一遍,事中会保留一些日志/截图之类的东西,事后再验证一下

缺点:

1. 个人不自信
2. 网络/底层方面的知识相对欠缺,目前也在去学习,积累

### 能做什么

1. 入职规范文档,比如运维需要用到哪些平台,要找哪些人申请权限
2. 运维故障、经验文档总结
3. 制定合理的扩缩容标准
4. 提升运维变更的自动化能力,比如中间件部署,常见变更等

### 问题

1. 针对大版本发布过程中,研发代码出bug,导致要一直发新包,在生产测试,这种情况怎么应对
1. 公司内部有部分应用，QPS很低，1秒有个10几次，但是部分接口请求时间超过5s，这种需要优化吗





### 遇到的故障

#### 1.问题现象:

* 安排晚上上线,研发最后再uat1环境测试,反馈uat1环境前端代码发布后,页面没有预期改变,怀疑jenkins有问题

#### 2.定位过程

1. 查看jenkins日志,发现一切正常
2. 登录ansible服务器,查看拉下来的代码包,git分支,以及版本号等,确认无误,反馈给研发,然后建议研发新增一个test文件,我重新发包
3. 新增test文件后,重新发包,test文件已发布,确认发布无误,研发坚持还是发包有问题
4. 找研发要了他新增的详细代码,去到ansible服务器上查到对应的代码,反馈给研发
5. 研发去dev环境验证,并说明dev1和uat1代码一样,但效果不一样,明确他那边没问题
6. 我让研发修改其他正常页面,如果有改变,说明他代码问题,如果没改变,说明不是代码问题
7. 修改正常页面后,还是没效果,我才认真考虑起这个问题
8. 查看cmdb前端配置,发现nginx配置都没点生成,一下明确,大概是运维侧的问题
9. 点击生成nginx配置后,再检查nginx配置,发现一切正常,再次发包,发现还是未生效
10. ping请求域名,发现域名的nginx地址与cmdb上生成的nginx地址不同
11. 将cmdb上该服务的前端地址绑定到与域名一致的服务器
12. 再次发包,前端界面显示预期结果

#### 3.问题原因

* 周一做了fat4和uat1环境的nginx迁移,将公司内部服务的域名全部部署到一台app服务器上,对外的域名,全部部署在一台nginx服务器上,配置文件都做了迁移,但是对应服务绑定的服务器没有修改
* 原nginx服务器上的前端代码都没有删除,所以正常的访问是可以,但是发布代码没效果

#### 4.导致后果

* 导致预计晚上发布的版本,没能发布,推迟一天

#### 5.思考

1. 本次问题定位,从一开始就被研发带偏,忽略了实际问题,耗费过多时间与研发争论jenkins发布是否正常
2. 到后面,其实已经觉得研发有点无理取闹,一直坚持定位问题的原因,是我自己想说服对方是他的错误
3. 反思一下,从个人性格来说,过程中有点急躁,后来就没有真心实意的去想着帮对方解决问题
4. 反思二下,忽略了对方的实际诉求是代码没生效,但是却把主焦点放在了jenkins上

